{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.applications import resnet\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import io, color\n",
    "from tensorflow.keras.layers import Lambda\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from PIL import Image\n",
    "from numpy import genfromtxt\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import shutil\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Out Components from Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Dataset/result_arv_model_11_11_2022.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "j = 0 #index for Body\n",
    "for i in range(len(data['ClassList'][j]['Data'])):\n",
    "\n",
    "    fileName = data['ClassList'][j]['Data'][i]['ViewInfo']['ViewName']\n",
    "    fileType = fileName+'_WhiteLight.jpg'\n",
    "    newX = data['ClassList'][j]['Data'][i]['Xmin'] - data['ClassList'][j]['Data'][i]['ViewInfo']['ViewX']\n",
    "    newY = data['ClassList'][j]['Data'][i]['Ymin'] - data['ClassList'][j]['Data'][i]['ViewInfo']['ViewY']\n",
    "    width = data['ClassList'][j]['Data'][i]['Width']\n",
    "    height = data['ClassList'][j]['Data'][i]['Height']\n",
    "    x1 = newX + (width)\n",
    "    y1 = newY + (height)\n",
    "    \n",
    "    image = cv2.imread('Dataset/Sample/Sample_3/W_N/'+fileName+'_W_N.jpg')\n",
    "    img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    crop_image = img_rgb[newY:int(y1), newX:int(x1)]\n",
    "    \n",
    "    cv2.imwrite('Dataset/Cropped_Body/img_'+str(i)+'.jpg', crop_image)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropped Image Data to Numpy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = [] #__________ for anchor\n",
    "temp_nameList = []\n",
    "test_list = [] #__________ for test set\n",
    "test_nameList = []\n",
    "img_label = [] #__________ img label\n",
    "file_nameList = []\n",
    "\n",
    "folder_directory1 = 'Imageset/Classified/a_T1/' #___________ Folder path\n",
    "ori_OR_sharp1 = input(\"1:Ori 2:Sharp\")\n",
    "rgb_OR_bgr1 = input(\"1: RGB, 2:BGR\")\n",
    "kernel1 = np.array([[0, -1, 0],\n",
    "                           [-1, 5,-1],\n",
    "                           [0, -1, 0]])\n",
    "count = 0\n",
    "for classified_folder in os.listdir(folder_directory1): #-------- looping \n",
    "    img_label2 = []\n",
    "    test_nameList2 = []\n",
    "    temp_nameList2 = []\n",
    "    file_nameList.append(classified_folder)\n",
    "    #____________ RESET LIST ___________#\n",
    "    temp_list =[]\n",
    "    test_list =[]\n",
    "    for img in os.listdir(folder_directory1+classified_folder): #-------- looping images in 12362362364\n",
    "        \n",
    "        #img_label2 = []\n",
    "        img_split_name = img.split('_')  # ------------------------------------ split file name\n",
    "        img_proc1 = cv2.imread(folder_directory1+classified_folder+'/'+img) #---- read img\n",
    "        if img == '.ipynb_checkpoints':\n",
    "            print('ignored .ipynb_checkpoints')\n",
    "        else:\n",
    "            if ori_OR_sharp1 == \"2\":   # ---------------- 1: Ori 2: Sharpen\n",
    "                img_proc1 = cv2.filter2D(src=img_proc1, ddepth=-1, kernel=kernel1)   \n",
    "            else:\n",
    "                img_proc1 = img_proc1\n",
    "\n",
    "            if rgb_OR_bgr1 == \"1\":  # ---------------- 1: RGB 2: BGR\n",
    "                img_proc1 = cv2.cvtColor(img_proc1, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            #_______________ ANCHOR ______________#\n",
    "            if img_split_name[0] == 'anchor':   \n",
    "                temp_list.append(img_proc1)\n",
    "                temp_nameList2.append(img)\n",
    "                #print(\"anchor\")\n",
    "            #_______________ DEFECT ______________#\n",
    "            elif img_split_name[0] == 'defect':\n",
    "                test_list.append(img_proc1)\n",
    "                test_nameList2.append(img)\n",
    "                img_label2.append(0)\n",
    "             #_______________ GOOD ______________#\n",
    "            elif img_split_name[0] == 'good':\n",
    "                test_list.append(img_proc1)\n",
    "                test_nameList2.append(img)\n",
    "                img_label2.append(1)\n",
    "                \n",
    "    temp_to_nparray = np.asarray(temp_list) #___________ list to numpy\n",
    "    test_to_nparray = np.asarray(test_list)\n",
    "\n",
    "    temp_output = temp_to_nparray/255\n",
    "    test_output = test_to_nparray/255\n",
    "\n",
    "\n",
    "    with open('Imageset/numpy/temp/set_'+str(count)+'.npy','wb') as temp_file: #_________save file\n",
    "        np.save(temp_file, temp_output)\n",
    "    with open('Imageset/numpy/test/set_'+str(count)+'.npy','wb') as test_file:\n",
    "        np.save(test_file, test_output)\n",
    "    print(test_output.shape)\n",
    "            \n",
    "            \n",
    "             \n",
    "    temp_nameList.append(temp_nameList2)\n",
    "    test_nameList.append(test_nameList2)\n",
    "    img_label.append(img_label2)\n",
    "    count += 1\n",
    "print('DONE')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################    IMAGE RESIZE  ################################# \n",
    "\n",
    "temp_list = [] #__________ for anchor\n",
    "temp_nameList = []\n",
    "test_list = [] #__________ for test set\n",
    "test_nameList = []\n",
    "img_label = [] #__________ img label\n",
    "file_nameList = []\n",
    "\n",
    "folder_directory1 = 'Imageset/Classified/a_T1/' #___________ Folder path\n",
    "ori_OR_sharp1 = input(\"1:Ori 2:Sharp\")\n",
    "rgb_OR_bgr1 = input(\"1: RGB, 2:BGR\")\n",
    "kernel1 = np.array([[0, -1, 0],\n",
    "                    [-1, 5,-1],\n",
    "                    [0, -1, 0]])\n",
    "\n",
    "npyTempFolder = 'Imageset/numpy/ori_bgr_temp7'\n",
    "npyTestFolder = 'Imageset/numpy/ori_bgr_test7'\n",
    "checknpyFolder  = os.path.isdir(npyTempFolder)\n",
    "if checknpyFolder == False:\n",
    "        os.mkdir(str(npyTempFolder))\n",
    "        os.mkdir(str(npyTestFolder))\n",
    "        \n",
    "count = 0\n",
    "for classified_folder in os.listdir(folder_directory1): #-------- looping 231274112387 in folder\n",
    "    img_label2 = []\n",
    "    test_nameList2 = []\n",
    "    temp_nameList2 = []\n",
    "    file_nameList.append(classified_folder)\n",
    "    #____________ RESET LIST ___________#\n",
    "    temp_list =[]\n",
    "    test_list =[]\n",
    "    temp_list2 =[]\n",
    "    test_list2 =[]\n",
    "    for img in os.listdir(folder_directory1+classified_folder): #-------- looping images in 12362362364\n",
    "        \n",
    "        #img_label2 = []\n",
    "        img_split_name = img.split('_')  # ------------------------------------ split file name\n",
    "        img_proc1 = cv2.imread(folder_directory1+classified_folder+'/'+img) #---- read img\n",
    "        if img == '.ipynb_checkpoints':\n",
    "            print('ignored .ipynb_checkpoints')\n",
    "        else:\n",
    "            if ori_OR_sharp1 == \"2\":   # ---------------- 1: Ori 2: Sharpen\n",
    "                img_proc1 = cv2.filter2D(src=img_proc1, ddepth=-1, kernel=kernel1)   \n",
    "            else:\n",
    "                img_proc1 = img_proc1\n",
    "\n",
    "            if rgb_OR_bgr1 == \"1\":  # ---------------- 1: RGB 2: BGR\n",
    "                img_proc1 = cv2.cvtColor(img_proc1, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "            ori_image_height, ori_image_width, ori_channels = img_proc1.shape\n",
    "            \n",
    "            if ori_image_height < 75 or ori_image_width < 75:  #resize image with any side <75 only\n",
    "                \n",
    "                if ori_image_height < ori_image_width:\n",
    "                    aspect_ratio = ori_image_width/ori_image_height\n",
    "                    new_image_width = 75*aspect_ratio\n",
    "                    img_proc11 = cv2.resize(img_proc1, (int(new_image_width),75))\n",
    "                elif ori_image_height > ori_image_width:\n",
    "                    aspect_ratio = ori_image_height/ori_image_width\n",
    "                    new_image_height = 75*aspect_ratio\n",
    "                    img_proc11 = cv2.resize(img_proc1, (75,int(new_image_height)))\n",
    "            else:\n",
    "                img_proc11 = img_proc1\n",
    "            \n",
    "            #_______________ ANCHOR ______________#\n",
    "            if img_split_name[0] == 'anchor':   \n",
    "                temp_list.append(img_proc11)\n",
    "                temp_nameList2.append(img)\n",
    "                temp_to_norma = img_proc11\n",
    "                temp_output = np.array(temp_to_norma)\n",
    "                temp_list2.append(temp_output)\n",
    "                #print(\"anchor\")\n",
    "            #_______________ DEFECT ______________#\n",
    "            elif img_split_name[0] == 'defect':\n",
    "                test_list.append(img_proc11)\n",
    "                test_nameList2.append(img)\n",
    "                img_label2.append(0)\n",
    "                test_to_norma = img_proc11\n",
    "                test_output = np.array(test_to_norma)\n",
    "                test_list2.append(test_output)\n",
    "             #_______________ GOOD ______________#\n",
    "            elif img_split_name[0] == 'good':\n",
    "                test_list.append(img_proc11)\n",
    "                test_nameList2.append(img)\n",
    "                img_label2.append(1)\n",
    "                test_to_norma = img_proc11\n",
    "                test_output = np.array(test_to_norma)\n",
    "                test_list2.append(test_output)\n",
    "    \n",
    "    with open(npyTempFolder+'/set_'+str(count)+'.npy','wb') as temp_file: #_________save file\n",
    "        np.save(temp_file, temp_list2)\n",
    "    with open(npyTestFolder+'/set_'+str(count)+'.npy','wb') as test_file:\n",
    "        np.save(test_file, test_list2)\n",
    "        \n",
    "    print(\"TEST:  \", temp_output.shape)\n",
    "    print(\"Template: \",test_output.shape)\n",
    "            \n",
    "            \n",
    "             \n",
    "    temp_nameList.append(temp_nameList2)\n",
    "    test_nameList.append(test_nameList2)\n",
    "    img_label.append(img_label2)\n",
    "    count += 1\n",
    "\n",
    "\n",
    "csv_fileName = input('filename: ')\n",
    "with open(csv_fileName, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=';')\n",
    "    for row in range(len(img_label)):\n",
    "        label_a = (img_label[row])\n",
    "        writer.writerow(label_a)\n",
    "        \n",
    "print('DONE')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(anchor, compare):\n",
    "    return K.sum(K.abs(anchor - compare), axis=1, keepdims=True)\n",
    "    #return sum(abs(a - b) for a, b in zip(point1, point2))\n",
    "\n",
    "def minkowski_distance(point1, point2, p):\n",
    "    return K.sum(K.abs(point1 - point2)**p, axis=-1)**(1/p)\n",
    "\n",
    "def cosine_similarity(x, y, p):\n",
    "    print(p)\n",
    "    x = K.l2_normalize(x, axis=-1)\n",
    "    y = K.l2_normalize(y, axis=-1)\n",
    "    return K.sum(x * y, axis=-1)\n",
    "\n",
    "def jaccard_similarity(x, y, p):\n",
    "    print(p)\n",
    "    intersection = K.sum(K.abs(x * y), axis=-1)\n",
    "    union = K.sum(K.abs(x) + K.abs(y), axis=-1) - intersection\n",
    "    return intersection / union\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Trained Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icp_V3_noTOP = tf.keras.applications.inception_v3.InceptionV3(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling='avg',\n",
    "    classes=1000,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "\n",
    "dnn_169_noTOP = tf.keras.applications.densenet.DenseNet169(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling='avg',\n",
    "    classes=1000,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "\n",
    "IR_V2_noTOP = tf.keras.applications.inception_resnet_v2.InceptionResNetV2(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling='avg',\n",
    "    classes=1000,\n",
    "    classifier_activation='softmax',)\n",
    "\n",
    "    #_________________get the model with prediction layer______________#\n",
    "ef_V2 = tf.keras.applications.efficientnet_v2.EfficientNetV2S(\n",
    "    include_top=True,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation='softmax',\n",
    "    include_preprocessing=True\n",
    ")\n",
    "\n",
    "#_________________get the model without prediction layer______________#\n",
    "ef_V2_noTOP = tf.keras.applications.efficientnet_v2.EfficientNetV2S(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation='softmax',\n",
    "    include_preprocessing=True\n",
    ")\n",
    "\n",
    "#_________________get the layer before prediction that missed out______________#\n",
    "ef_v2_avgpool = ef_V2.get_layer('avg_pool')\n",
    "ef_v2_dropout = ef_V2.get_layer('top_dropout')\n",
    "\n",
    "\n",
    "#_________________combined them as a new model______________#\n",
    "ef_v2_final = ef_v2_avgpool(ef_V2_noTOP.output)\n",
    "ef_v2_final = ef_v2_dropout(ef_v2_final)\n",
    "\n",
    "new_ef_V2_model = Model(inputs=ef_V2_noTOP.inputs, outputs=ef_v2_final, name = \"EF_V2\")\n",
    "\n",
    "#_________________importing without the prediction will miss out some of the fully connected layers______________#\n",
    "#_________________importing with the prediction will need to specify the input size______________#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Distance Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_Type = input(\"Distance Type to use: \\n1: Minkowski Distance\\n2: Cosine Similarity\\n3: Jaccard Similarity\\n\")\n",
    "model_Choice =  input(\"Model Type to use: \\n1: DenseNet\\n2: EfficientNet\\n3: Inception\\n4: InceptionResNet\\n\")                   \n",
    "test_Type = input(\"\\n\\n1: 1 to 1 Image\\n2: 1 to All Image\\n3: ALL to ALL\")\n",
    "test_set = input(\"\\ntest set: \\n\")\n",
    "black = [1,2,5,7]                      \n",
    "d = []\n",
    "d2 = []\n",
    "if int(model_Choice) == 1:\n",
    "    Model_toPrint = (\"DenseNet\")\n",
    "    model_type = dnn_169_noTOP\n",
    "elif int(model_Choice) == 2:\n",
    "    Model_toPrint = (\"EfficientNet\")\n",
    "    model_type = new_ef_V2_model\n",
    "elif int(model_Choice) == 3:\n",
    "    Model_toPrint = (\"Inception V3\")\n",
    "    model_type = icp_V3_noTOP\n",
    "elif int(model_Choice) == 4:\n",
    "    Model_toPrint = (\"InceptionResNet V2\")\n",
    "    model_type = IR_V2_noTOP\n",
    "    \n",
    "if int(distance_Type) == 1:\n",
    "    Distance_toPrint = (\"Minkowski Distance\")\n",
    "    p_value = input(\"P value:\\n1: Mahathan\\n2: Euclidean\\n\")\n",
    "    distance_type = minkowski_distance\n",
    "elif int(distance_Type) == 2:\n",
    "    Distance_toPrint = (\"Cosine Similarity\")\n",
    "    distance_type = cosine_similarity\n",
    "elif int(distance_Type) == 3:\n",
    "    Distance_toPrint = (\"Jaccard Similarity\")\n",
    "    distance_type = jaccard_similarity\n",
    "#elif int(distance_Type) == 3:\n",
    "    #distance_type = DistanceLayer()\n",
    "print(Model_toPrint, \"\\t\",Distance_toPrint, \"\\n\")\n",
    "imgnp_test = np.load('Dataset/'+test_set+'.npy', allow_pickle=True)\n",
    "imgnp = np.load('Dataset/temp111.npy', allow_pickle=True)                      \n",
    "if int(test_Type) == 1:\n",
    "                      \n",
    "    #_________________Load Images______________#\n",
    "    \n",
    "    img_no = input(\"\\ntemplate img no: \")\n",
    "    img_no2 = input(\"\\nquery img no: \")                  \n",
    "    #_________________tiling images, model only takes vector size of 4, image only have 3______________#\n",
    "    imgt1 = (np.tile(imgnp[int(img_no)],(1,1,1,1)))\n",
    "    imgt2 = (np.tile(imgnp[xx],(1,1,1,1)))\n",
    "\n",
    "    #_________________getting the vectors______________#\n",
    "    pred1 = model_type.predict(imgt1)\n",
    "    pred2 = model_type.predict(imgt2)\n",
    "\n",
    "    #_________________getting the distance______________#\n",
    "    distances = distance_type(pred1,pred2,int(p_value))\n",
    "    distances2 = DistanceLayer()(pred1,pred2)                  \n",
    "    print(distances)\n",
    "    plt.imshow(imgnp[int(img_no)])\n",
    "    plt.show()\n",
    "    plt.imshow(imgnp[int(img_no2)])\n",
    "    plt.show()\n",
    "                      \n",
    "elif int(test_Type) == 2:\n",
    "                      \n",
    "    img_no3 = input(\"\\nquery img no: \")\n",
    "        \n",
    "    for xx in range(len(imgnp_test)):\n",
    "                      \n",
    "        #_________________tiling images, model only takes vector size of 4, image only have 3______________#\n",
    "        imgt1 = (np.tile(imgnp[int(img_no3)],(1,1,1,1)))\n",
    "        imgt2 = (np.tile(imgnp_test[xx],(1,1,1,1)))\n",
    "\n",
    "        #_________________getting the vectors______________#\n",
    "        pred1 = model_type.predict(imgt1)\n",
    "        pred2 = model_type.predict(imgt2)\n",
    "\n",
    "        #_________________getting the distance______________#\n",
    "        distances = distance_type(pred1,pred2,int(p_value))\n",
    "        distances2 = DistanceLayer()(pred1,pred2) \n",
    "        print(distances)\n",
    "        distance_numpy = distances.numpy()\n",
    "        d.append(distance_numpy[0])\n",
    "        print(xx)\n",
    "        plt.imshow(imgnp_test[xx])\n",
    "        plt.show()\n",
    "\n",
    "elif int(test_Type) == 3:\n",
    "    \n",
    "    for yy in range(len(imgnp)):\n",
    "        d3 = []\n",
    "        for xx in range(len(imgnp_test)):\n",
    "            #_________________tiling images, model only takes vector size of 4, image only have 3______________#\n",
    "            imgt1 = (np.tile(imgnp[yy],(1,1,1,1)))\n",
    "            imgt2 = (np.tile(imgnp_test[xx],(1,1,1,1)))\n",
    "\n",
    "            #_________________getting the vectors______________#\n",
    "            pred1 = model_type.predict(imgt1)\n",
    "            pred2 = model_type.predict(imgt2)\n",
    "\n",
    "            #_________________getting the distance______________#\n",
    "            distances = distance_type(pred1,pred2,int(p_value))\n",
    "            print(distances)\n",
    "            distance_numpy = distances.numpy()\n",
    "            d.append(distance_numpy[0])\n",
    "            d3.append(distance_numpy[0])\n",
    "            #d3.append(distance_numpy[0])\n",
    "            print(xx)\n",
    "            plt.imshow(imgnp_test[xx])\n",
    "            plt.show()\n",
    "        d2.append(d3)\n",
    "else:\n",
    "    test_set2 = input(\"test set 2: \")\n",
    "    imgnp_test2 = np.load('Dataset/'+test_set2+'.npy', allow_pickle=True)\n",
    "    d4 = []\n",
    "    d5 = []\n",
    "    \n",
    "    for yy in range(len(imgnp)):\n",
    "        \n",
    "        d3 = []\n",
    "        for xx in range(len(imgnp_test)):\n",
    "            #_________________tiling images, model only takes vector size of 4, image only have 3______________#\n",
    "            imgt1 = (np.tile(imgnp[yy],(1,1,1,1)))\n",
    "            imgt2 = (np.tile(imgnp_test[xx],(1,1,1,1)))\n",
    "\n",
    "            #_________________getting the vectors______________#\n",
    "            pred1 = model_type.predict(imgt1)\n",
    "            pred2 = model_type.predict(imgt2)\n",
    "\n",
    "            #_________________getting the distance______________#\n",
    "            distances = distance_type(pred1,pred2,int(p_value))\n",
    "            print(distances)\n",
    "            distance_numpy = distances.numpy()\n",
    "            d.append(distance_numpy[0])\n",
    "            d3.append(distance_numpy[0])\n",
    "\n",
    "        d2.append(d3)\n",
    "        \n",
    "    for yyy in range(len(imgnp)):\n",
    "        \n",
    "        d6 = []\n",
    "        for xxx in range(len(imgnp_test2)):\n",
    "            #_________________tiling images, model only takes vector size of 4, image only have 3______________#\n",
    "            imgt1s = (np.tile(imgnp[yyy],(1,1,1,1)))\n",
    "            imgt2s = (np.tile(imgnp_test2[xxx],(1,1,1,1)))\n",
    "\n",
    "            #_________________getting the vectors______________#\n",
    "            pred1s = model_type.predict(imgt1s)\n",
    "            pred2s = model_type.predict(imgt2s)\n",
    "\n",
    "            #_________________getting the distance______________#\n",
    "            distancess = distance_type(pred1s,pred2s,int(p_value))\n",
    "            print(distancess)\n",
    "            distance_numpys = distancess.numpy()\n",
    "            d4.append(distance_numpys[0])\n",
    "            d6.append(distance_numpys[0])\n",
    "            \n",
    "        d5.append(d6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_max_list = []\n",
    "auc_not_list = []\n",
    "#______________________________   Temp vs Test   ______________________________#\n",
    "\n",
    "model_Choice =  input(\"Model Type to use: \\n1: DenseNet\\n2: EfficientNet\\n3: Inception\\n4: InceptionResNet\\n\")                   \n",
    "p_value = 2\n",
    "\n",
    "if int(model_Choice) == 1:\n",
    "    Model_toPrint = (\"DenseNet\")\n",
    "    model_type = dnn_169_noTOP\n",
    "elif int(model_Choice) == 2:\n",
    "    Model_toPrint = (\"EfficientNet\")\n",
    "    model_type = new_ef_V2_model\n",
    "elif int(model_Choice) == 3:\n",
    "    Model_toPrint = (\"Inception V3\")\n",
    "    model_type = icp_V3_noTOP\n",
    "elif int(model_Choice) == 4:\n",
    "    Model_toPrint = (\"InceptionResNet V2\")\n",
    "    model_type = IR_V2_noTOP\n",
    "\n",
    "d_list = []\n",
    "d_list2=[]\n",
    "\n",
    "start_time = time.time()\n",
    "for temp_test in tqdm (range(251), desc=\"Loading...\"):\n",
    "    if temp_test == 177 or temp_test == 190:\n",
    "        print(\"ignored\")\n",
    "    else:\n",
    "        temp2 = np.load('Imageset/numpy/ori_bgr_temp7/set_'+str(temp_test)+'.npy')\n",
    "        test2 = np.load('Imageset/numpy/ori_bgr_test7/set_'+str(temp_test)+'.npy')\n",
    "        #true_label = img_label[temp_test]\n",
    "        #print(true_label)\n",
    "        for yy in range(len(temp2)):\n",
    "            d_list=[]\n",
    "            for xx in range(len(test2)):\n",
    "                #plt.imshow(temp2[yy])\n",
    "                #plt.show()\n",
    "                #plt.imshow(test2[xx])\n",
    "                #plt.show()\n",
    "                img1 = (np.tile(temp2[yy],(1,1,1,1)))\n",
    "                img2 = (np.tile(test2[xx],(1,1,1,1)))\n",
    "\n",
    "                pred4 = model_type.predict(img1, verbose = 0)\n",
    "                pred5 = model_type.predict(img2, verbose = 0)\n",
    "                #pred5 = icp_V3_noTOP.predict(img2)\n",
    "\n",
    "                            #_________________getting the distance______________#\n",
    "                distances = minkowski_distance(pred4,pred5,p_value)\n",
    "                #print(distances)\n",
    "                distance_numpys = distances.numpy()\n",
    "                #d4.append(distance_numpys[0])\n",
    "                d_list.append(distance_numpys[0])\n",
    "            d_list2.append(d_list)\n",
    "    pass\n",
    "\n",
    "print(\"END TIME FOR Temp Vs Test: --- %s seconds ---\" % (time.time() - start_time))        \n",
    "    #print(d_list)\n",
    "    #print(temp2.shape)\n",
    "    #print(temp_test)\n",
    "    \n",
    "#______________________________   Temp vs Temp   ______________________________#\n",
    "\n",
    "start_time2 = time.time()    \n",
    "d_list_MAX = []\n",
    "d_list2_MAX=[]\n",
    "#for i in tqdm (range (1), desc=\"Loading...\"):\n",
    "    #for temp_test_MAX in range(251):\n",
    "for temp_test_MAX in tqdm (range(251), desc=\"Loading...\"):\n",
    "    if temp_test_MAX == 177 or temp_test_MAX == 190:\n",
    "        print(\"ignored\")\n",
    "    else:\n",
    "        temp2_MAX = np.load('Imageset/numpy/ori_bgr_temp7/set_'+str(temp_test_MAX)+'.npy')\n",
    "        test2_MAX = np.load('Imageset/numpy/ori_bgr_temp7/set_'+str(temp_test_MAX)+'.npy')\n",
    "        #true_label = img_label_removed[temp_test]\n",
    "        #print(true_label)\n",
    "        for yy_MAX in range(len(temp2_MAX)):\n",
    "            d_list_MAX=[]\n",
    "            for xx_MAX in range(len(test2_MAX)):\n",
    "                #plt.imshow(temp2[yy])\n",
    "                #plt.show()\n",
    "                #plt.imshow(test2[xx])\n",
    "                #plt.show()\n",
    "                img1_MAX = (np.tile(temp2_MAX[yy_MAX],(1,1,1,1)))\n",
    "                img2_MAX = (np.tile(test2_MAX[xx_MAX],(1,1,1,1)))\n",
    "\n",
    "                pred4_MAX = model_type.predict(img1_MAX, verbose = 0)\n",
    "                pred5_MAX = model_type.predict(img2_MAX, verbose = 0)\n",
    "                #pred5 = icp_V3_noTOP.predict(img2)\n",
    "\n",
    "                            #_________________getting the distance______________#\n",
    "                distances_MAX = minkowski_distance(pred4_MAX,pred5_MAX,p_value)\n",
    "                #print(distances)\n",
    "                distance_numpys_MAX = distances_MAX.numpy()\n",
    "                #d4.append(distance_numpys[0])\n",
    "                d_list_MAX.append(distance_numpys_MAX[0])\n",
    "            d_list2_MAX.append(d_list_MAX)\n",
    "    #print(d_list_MAX)\n",
    "    #print(temp2_MAX.shape)\n",
    "    #print(temp_test_MAX)\n",
    "    pass\n",
    "print(\"END TIME FOR Temp Vs Temp: --- %s seconds ---\" % (time.time() - start_time2))\n",
    "\n",
    "\n",
    "#______________________________   AUC without Threshold   ______________________________#\n",
    "\n",
    "average_list2 = []\n",
    "fprs_list = []\n",
    "tprs_list = []\n",
    "jjj = 0\n",
    "auc = 0\n",
    "kt = 0\n",
    "ign = 0\n",
    "score75 = []\n",
    "score75no = []\n",
    "for jjj in range(0,747,3):\n",
    "    average_list = []\n",
    "    auc2 = 0\n",
    "    \n",
    "    for jj in range(len(d_list2[0])):\n",
    "        average_score = (d_list2[jjj][jj]+d_list2[jjj+1][jj]+d_list2[jjj+2][jj])/3\n",
    "        average_list.append(average_score)\n",
    "\n",
    "    \n",
    "    average_list2.append(average_list)\n",
    "    \n",
    "for kkk in range(len(average_list2)):\n",
    "    if img_label_removed[kkk] == [1,1,1,1] or img_label_removed[kkk] == [0,0,0,0]:\n",
    "        ign = ign + 1\n",
    "        auc_not_list.append(2)\n",
    "    else:\n",
    "        kt = kt + 1\n",
    "        auc2 = roc_auc_score(img_label_removed[kkk], average_list2[kkk])\n",
    "        reverse_auc = 1-auc2\n",
    "        fpr, tpr, _ = roc_curve(img_label_removed[kkk], average_list2[kkk])\n",
    "        fprs_list.append(fpr)\n",
    "        tprs_list.append(tpr)\n",
    "        #auc_max_list.append(auc_max) \n",
    "        auc_not_list.append(reverse_auc)\n",
    "        auc = auc + reverse_auc\n",
    "        if reverse_auc < 0.76:\n",
    "            score75.append(reverse_auc)\n",
    "            score75no.append(kkk)\n",
    "        \n",
    "print(len(img_label_removed))\n",
    "print('_______________________________ WIHOUT THRESHOLD _______________________________')\n",
    "print('AVERAGE AUC: ', auc/kt)\n",
    "print('AVERAGE AUC WITH ALL TRUE: ', (auc+ign)/249)\n",
    "print('ALL TRUE: ', ign)\n",
    "\n",
    "#______________________________   AUC with MAX Threshold   ______________________________#\n",
    "\n",
    "########################################################################   FIND MAX SCORE FOR AS THRESHOLD  #########################################\n",
    "d_max3 = []\n",
    "d_max2 = []\n",
    "d_max1 = []\n",
    "for dist in (d_list2_MAX):\n",
    "    d_max1.append(max(dist))\n",
    "    \n",
    "for lll in range(0,747,3):\n",
    "    d_max2 = []\n",
    "    d_max = 0 \n",
    "    pp = 0\n",
    "    for nn in range(3): \n",
    "        if d_max < d_max1[nn+lll]:\n",
    "\n",
    "            d_max = d_max1[nn+lll]\n",
    "\n",
    "        else:\n",
    "            pp = pp + 1\n",
    "    d_max2.append(d_max)\n",
    "\n",
    "    d_max3.append(d_max2)\n",
    "\n",
    "\n",
    "########################################################################   MAX THRESHOLD   ##################################################################################\n",
    "pred_label = []\n",
    "\n",
    "count_pred = 0\n",
    "for comp in average_list2:\n",
    "    pred_label2 = []\n",
    "    for score in comp:\n",
    "        if score < d_max3[count_pred]:\n",
    "            pred_label2.append(1)\n",
    "        elif score > d_max3[count_pred]:\n",
    "            pred_label2.append(0)\n",
    "    count_pred = count_pred + 1\n",
    "    pred_label.append(pred_label2)\n",
    "    \n",
    "########################################################################   FIND AUC   ##################################################################################\n",
    "ign_max = 0\n",
    "auc_count_max = 0\n",
    "auc_max = 0\n",
    "low_auc_imgno = []\n",
    "low_auc_score = []\n",
    "fprs_max_list = []\n",
    "tprs_max_list = []\n",
    "for qqq in range(249):\n",
    "    if img_label_removed[qqq] == [1,1,1,1] or img_label_removed[qqq] == [0,0,0,0]:\n",
    "        #print(\"ignore\")\n",
    "        ign_max = ign_max + 1\n",
    "    else:\n",
    "        auc_count_max = auc_count_max + 1\n",
    "        auc2_max = roc_auc_score(img_label_removed[qqq], pred_label[qqq])\n",
    "        \n",
    "        fpr_max, tpr_max, _ = roc_curve(img_label_removed[qqq], pred_label[qqq])\n",
    "        fprs_max_list.append(fpr_max)\n",
    "        tprs_max_list.append(tpr_max)\n",
    "        auc_max_list.append(auc2_max)\n",
    "        auc_max = auc_max + auc2_max\n",
    "        if auc2_max < 0.4:\n",
    "            low_auc_score.append(auc2_max)\n",
    "            low_auc_imgno.append(qqq)\n",
    "print('_______________________________ MAX THRESHOLD _______________________________')\n",
    "print(len(img_label_removed))\n",
    "print('AVERAGE AUC: ', auc_max/auc_count_max)\n",
    "print('AVERAGE AUC WITH ALL TRUE: ', (auc_max+ign_max)/249)\n",
    "\n",
    "########################################################################   export to CSV   ##################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
